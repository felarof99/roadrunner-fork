trainer_dir: "/mnt/persistent-disk/test/"
export_dir: "/mnt/persistent-disk/test/hf_export"
hf_token: "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"
hf_model_download_token: "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"
hf_repo: "felarof01/test-model"
test_mode: true

data_config:
  data_source: "/home/felafax/trainers/cli_tuner/test_data.jsonl"
  batch_size: 8
  max_seq_length: 4096
  num_workers: 8
  mask_prompt: false
  dataset_input_field: "instruction"
  dataset_output_field: "output"
  split: "train"

trainer_config:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  param_dtype: "bfloat16"
  compute_dtype: "bfloat16"
  num_epochs: 1
  num_steps: 100
  num_tpus: 8  # or use jax.device_count()
  learning_rate: 1e-3
  lora_rank: 16
  use_lora: true
  log_interval: 5
  eval_interval: 5
  eval_steps: 10
  restore_checkpoint: false
  base_dir: "/mnt/persistent-disk"

checkpointer_config:
  checkpoint_dir: ""  # This will be set in __post_init__
  max_to_keep: 2
  save_interval_steps: 50
  enable_async_checkpointing: true
  erase_existing_checkpoints: true