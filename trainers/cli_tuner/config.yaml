trainer_dir: "/mnt/persistent-disk/test/"
export_dir: "/mnt/persistent-disk/test/hf_export"
hf_token: "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"
hf_model_download_token: "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"
hf_repo: "felarof01/test-model"
test_mode: true

data_config:
  data_source: "/home/dataset/test.jsonl"
  batch_size: 8
  max_seq_length: 32
  dataset_input_field: "input"
  dataset_output_field: "response"

trainer_config:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  param_dtype: "bfloat16"
  compute_dtype: "bfloat16"
  num_epochs: 1
  num_steps: 5
  learning_rate: 1e-3
  lora_rank: 16
  use_lora: true
  log_interval: 5
  eval_interval: 5
  eval_steps: 10


checkpointer_config:
  save_interval_steps: 100